{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Lab\n",
    "\n",
    "You will find in this notebook some scrapy exercises to practise your scraping skills.\n",
    "\n",
    "**Tips:**\n",
    "\n",
    "- Check the response status code for each request to ensure you have obtained the intended contennt.\n",
    "- Print the response text in each request to understand the kind of info you are getting and its format.\n",
    "- Check for patterns in the response text to extract the data/info requested in each question.\n",
    "- Visit each url and take a look at its source through Chrome DevTools. You'll need to identify the html tags, special class names etc. used for the html content you are expected to extract."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Requests library](http://docs.python-requests.org/en/master/#the-user-guide) documentation \n",
    "- [Beautiful Soup Doc](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- [Urllib](https://docs.python.org/3/library/urllib.html#module-urllib)\n",
    "- [re lib](https://docs.python.org/3/library/re.html)\n",
    "- [lxml lib](https://lxml.de/)\n",
    "- [Scrapy](https://scrapy.org/)\n",
    "- [List of HTTP status codes](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)\n",
    "- [HTML basics](http://www.simplehtmlguide.com/cheatsheet.php)\n",
    "- [CSS basics](https://www.cssbasics.com/#page_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below are the libraries and modules you may need. `requests`,  `BeautifulSoup` and `pandas` are imported for you. If you prefer to use additional libraries feel free to uncomment them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as r\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "import lxml\n",
    "# from pprint import pprint\n",
    "# from lxml import html\n",
    "# from lxml.html import fromstring\n",
    "# import urllib.request\n",
    "# from urllib.request import urlopen\n",
    "# import scrapy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download, parse (using BeautifulSoup), and print the content from the Trending Developers page from GitHub:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the names of the trending developers retrieved in the previous step.\n",
    "\n",
    "Your output should be a Python list of developer names. Each name should not contain any html tag.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Find out the html tag and class names used for the developer names. You can achieve this using Chrome DevTools.\n",
    "\n",
    "1. Use BeautifulSoup to extract all the html elements that contain the developer names.\n",
    "\n",
    "1. Use string manipulation techniques to replace whitespaces and linebreaks (i.e. `\\n`) in the *text* of each html element. Use a list to store the clean names.\n",
    "\n",
    "1. Print the list of names.\n",
    "\n",
    "Your output should look like below:\n",
    "\n",
    "```\n",
    "['trimstray (@trimstray)',\n",
    " 'joewalnes (JoeWalnes)',\n",
    " 'charlax (Charles-AxelDein)',\n",
    " 'ForrestKnight (ForrestKnight)',\n",
    " 'revery-ui (revery-ui)',\n",
    " 'alibaba (Alibaba)',\n",
    " 'Microsoft (Microsoft)',\n",
    " 'github (GitHub)',\n",
    " 'facebook (Facebook)',\n",
    " 'boazsegev (Bo)',\n",
    " 'google (Google)',\n",
    " 'cloudfetch',\n",
    " 'sindresorhus (SindreSorhus)',\n",
    " 'tensorflow',\n",
    " 'apache (TheApacheSoftwareFoundation)',\n",
    " 'DevonCrawford (DevonCrawford)',\n",
    " 'ARMmbed (ArmMbed)',\n",
    " 'vuejs (vuejs)',\n",
    " 'fastai (fast.ai)',\n",
    " 'QiShaoXuan (Qi)',\n",
    " 'joelparkerhenderson (JoelParkerHenderson)',\n",
    " 'torvalds (LinusTorvalds)',\n",
    " 'CyC2018',\n",
    " 'komeiji-satori (神楽坂覚々)',\n",
    " 'script-8']\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mafintosh (Mathias Buus)',\n",
       " 'vitorgalvao (Vítor Galvão)',\n",
       " 'ZacSweers (Zac Sweers)',\n",
       " 'XhmikosR (XhmikosR)',\n",
       " 'philsturgeon (Phil Sturgeon)',\n",
       " 'DanTup (Danny Tuppeny)',\n",
       " 'kishikawakatsumi (Kishikawa Katsumi)',\n",
       " 'scottaddie (Scott Addie)',\n",
       " 'mpociot (Marcel Pociot)',\n",
       " 'bcoe (Benjamin E. Coe)',\n",
       " 'qwwdfsad (Vsevolod Tolstopyatov)',\n",
       " 'MarshallOfSound (Samuel Attard)',\n",
       " 'amueller (Andreas Mueller)',\n",
       " 'rogpeppe (Roger Peppe)',\n",
       " 'grosser (Michael Grosser)',\n",
       " 'timothycrosley (Timothy Edmund Crosley)',\n",
       " 'kripken (Alon Zakai)',\n",
       " 'fzaninotto (Francois Zaninotto)',\n",
       " 'etpinard ( Étienne Tétreault-Pinard)',\n",
       " 'ycjcl868 (信鑫-King)',\n",
       " 'hanxiao (Han Xiao)',\n",
       " 'prescottprue (Scott Prue)',\n",
       " 'artf (Artur Arseniev)',\n",
       " 'mathiasbynens (Mathias Bynens)',\n",
       " 'ekg (Erik Garrison)']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://github.com/trending/developers'\n",
    "soup = bs(r.get(url).content, 'lxml')\n",
    "developers = pd.Series([str(i) for i in soup.find_all('h1', {'class': 'h3 lh-condensed'})])\n",
    "developers = developers.str.replace('<h1 class=\"h3 lh-condensed\"><a href=\"/', '').str.replace('\">', ' (').str.replace('</a></h1>', ')').to_list()\n",
    "\n",
    "developers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the trending Python repositories in GitHub\n",
    "\n",
    "The steps to solve this problem is similar to the previous one except that you need to find out the repository names instead of developer names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PhantomInsights/mexican-government-report',\n",
       " 'CorentinJ/Real-Time-Voice-Cloning',\n",
       " 'yossigandelsman/DoubleDIP',\n",
       " 'donnemartin/system-design-primer',\n",
       " 'google-research/bert',\n",
       " 'public-apis/public-apis',\n",
       " 'OWASP/CheatSheetSeries',\n",
       " 'apachecn/AiLearning',\n",
       " '30-seconds/30-seconds-of-python',\n",
       " 'd2l-ai/d2l-en',\n",
       " 'fighting41love/funNLP',\n",
       " 'django/django',\n",
       " '0voice/interview_internal_reference',\n",
       " 'tensorflow/models',\n",
       " 'huggingface/pytorch-transformers',\n",
       " 'gnebbia/pdlist',\n",
       " 'tensorflow/agents',\n",
       " 'd2l-ai/d2l-zh',\n",
       " 'RasaHQ/rasa',\n",
       " 'pandas-dev/pandas',\n",
       " 'Jrohy/multi-v2ray',\n",
       " 'shadowsocksr-backup/shadowsocksr',\n",
       " 'tkipf/pygcn',\n",
       " 'shadowsocks/shadowsocks',\n",
       " 'mlflow/mlflow']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://github.com/trending/python?since=daily'\n",
    "soup = bs(r.get(url).content, 'lxml')\n",
    "repos = pd.Series([str(i) for i in soup.find_all('h1', {'class': 'h3 lh-condensed'})]).str.replace('^(?:.|\\n)*href=\"/', '').str.replace('\"(?:.|\\n)*$', '').to_list()\n",
    "repos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display all the image links from Walt Disney wikipedia page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://en.wikipedia.org/wiki/File:Walt_Disney_1946.JPG',\n",
       " 'https://en.wikipedia.org/wiki/File:Walt_Disney_1942_signature.svg',\n",
       " 'https://en.wikipedia.org/wiki/File:Walt_Disney_envelope_ca._1921.jpg',\n",
       " 'https://en.wikipedia.org/wiki/File:Trolley_Troubles_poster.jpg',\n",
       " 'https://en.wikipedia.org/wiki/File:Walt_Disney_and_his_cartoon_creation_%22Mickey_Mouse%22_-_National_Board_of_Review_Magazine.jpg',\n",
       " 'https://en.wikipedia.org/wiki/File:Steamboat-willie.jpg',\n",
       " 'https://en.wikipedia.org/wiki/File:Walt_Disney_1935.jpg',\n",
       " 'https://en.wikipedia.org/wiki/File:Walt_Disney_Snow_white_1937_trailer_screenshot_(13).jpg',\n",
       " 'https://en.wikipedia.org/wiki/File:Disney_drawing_goofy.jpg',\n",
       " 'https://en.wikipedia.org/wiki/File:DisneySchiphol1951.jpg',\n",
       " 'https://en.wikipedia.org/wiki/File:WaltDisneyplansDisneylandDec1954.jpg',\n",
       " 'https://en.wikipedia.org/wiki/File:Walt_disney_portrait_right.jpg',\n",
       " 'https://en.wikipedia.org/wiki/File:Walt_Disney_Grave.JPG',\n",
       " 'https://en.wikipedia.org/wiki/File:Roy_O._Disney_with_Company_at_Press_Conference.jpg',\n",
       " 'https://en.wikipedia.org/wiki/File:Disney_Display_Case.JPG',\n",
       " 'https://en.wikipedia.org/wiki/File:Disney1968.jpg',\n",
       " 'https://en.wikipedia.org/wiki/File:Animation_disc.svg',\n",
       " 'https://en.wikipedia.org/wiki/File:P_vip.svg',\n",
       " 'https://en.wikipedia.org/wiki/File:Magic_Kingdom_castle.jpg',\n",
       " 'https://en.wikipedia.org/wiki/File:Video-x-generic.svg',\n",
       " 'https://en.wikipedia.org/wiki/File:Flag_of_Los_Angeles_County,_California.svg',\n",
       " 'https://en.wikipedia.org/wiki/File:Blank_television_set.svg',\n",
       " 'https://en.wikipedia.org/wiki/File:Flag_of_the_United_States.svg']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/Walt_Disney'\n",
    "soup = bs(r.get(url).content, 'lxml')\n",
    "images = ('https://en.wikipedia.org' + pd.Series([str(i) for i in soup.find_all('a', {'class': 'image'})]).str.replace('^(?:.|\\n)*href=\"', '').str.replace('\"(?:.|\\n)*$', '')).to_list()\n",
    "images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve an arbitary Wikipedia page of \"Python\" and create a list of links on that page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           https://en.wikipedia.org/wiki/Python#mw-head\n",
       "1          https://en.wikipedia.org/wiki/Python#p-search\n",
       "2                  https://en.wiktionary.org/wiki/Python\n",
       "3                  https://en.wiktionary.org/wiki/python\n",
       "4            https://en.wikipedia.org/wiki/Python#Snakes\n",
       "                             ...                        \n",
       "151    https://www.mediawiki.org/wiki/Special:MyLangu...\n",
       "152    https://foundation.wikimedia.org/wiki/Cookie_s...\n",
       "153    https://en.m.wikipedia.org/w/index.php?title=P...\n",
       "154                     https://wikimediafoundation.org/\n",
       "155                           https://www.mediawiki.org/\n",
       "Length: 156, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url ='https://en.wikipedia.org/wiki/Python'\n",
    "soup = bs(r.get(url).content, 'lxml')\n",
    "links = pd.Series([str(i) for i in soup.find_all('a') if str(i) != '<a id=\"top\"></a>']).str.replace('^(?:.|\\n)*href=\"', '').str.replace('\"(?:.|\\n)*$', '')\n",
    "links[links.str.contains('^#')] = 'https://en.wikipedia.org/wiki/Python' + links\n",
    "links[links.str.contains('^/{1}[A-z]')] = 'https://en.wikipedia.org/wiki' + links\n",
    "links[links.str.contains('^/{2}')] = 'https:' + links\n",
    "links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Titles that have changed in the United States Code since its last release point "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'http://uscode.house.gov/download/download.shtml'\n",
    "soup = bs(r.get(url).content, 'lxml')\n",
    "titles = pd.Series([str(i) for i in soup.find_all('div', 'usctitlechanged')])\n",
    "len(titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Python list with the top ten FBI's Most Wanted names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ARNOLDO JIMENEZ',\n",
       " 'ALEJANDRO ROSALES CASTILLO',\n",
       " 'YASER ABDEL SAID',\n",
       " 'JASON DEREK BROWN',\n",
       " 'ALEXIS FLORES',\n",
       " 'EUGENE PALMER',\n",
       " 'SANTIAGO VILLALBA MEDEROS',\n",
       " 'RAFAEL CARO-QUINTERO',\n",
       " 'ROBERT WILLIAM FISHER',\n",
       " 'BHADRESHKUMAR CHETANBHAI PATEL']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.fbi.gov/wanted/topten'\n",
    "soup = bs(r.get(url).content, 'lxml')\n",
    "fbi = pd.Series([str(i) for i in soup.find_all('h3', 'title')]).str.split('>')\n",
    "fbi_names = pd.Series([i[2] for i in fbi]).str.strip('</a').to_list()\n",
    "fbi_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  20 latest earthquakes info (date, time, latitude, longitude and region name) by the EMSC as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2019-09-19</td>\n",
       "      <td>17:55:15.0</td>\n",
       "      <td>2.04S</td>\n",
       "      <td>81.04W</td>\n",
       "      <td>NEAR COAST OF ECUADOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-09-19</td>\n",
       "      <td>16:51:11.8</td>\n",
       "      <td>38.34N</td>\n",
       "      <td>121.50W</td>\n",
       "      <td>CENTRAL ALASKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-09-19</td>\n",
       "      <td>16:43:38.0</td>\n",
       "      <td>19.64N</td>\n",
       "      <td>69.58W</td>\n",
       "      <td>NORTHERN CALIFORNIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-09-19</td>\n",
       "      <td>15:42:11.5</td>\n",
       "      <td>30.44S</td>\n",
       "      <td>117.66E</td>\n",
       "      <td>ISLAND OF HAWAII, HAWAII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019-09-19</td>\n",
       "      <td>15:04:22.0</td>\n",
       "      <td>41.84N</td>\n",
       "      <td>14.85E</td>\n",
       "      <td>DOMINICAN REPUBLIC REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2019-09-19</td>\n",
       "      <td>14:34:54.4</td>\n",
       "      <td>58.36N</td>\n",
       "      <td>155.89W</td>\n",
       "      <td>TONGA REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2019-09-19</td>\n",
       "      <td>14:29:59.6</td>\n",
       "      <td>35.06N</td>\n",
       "      <td>117.46W</td>\n",
       "      <td>WESTERN AUSTRALIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2019-09-19</td>\n",
       "      <td>14:07:19.0</td>\n",
       "      <td>21.84S</td>\n",
       "      <td>68.51W</td>\n",
       "      <td>WESTERN TURKEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2019-09-19</td>\n",
       "      <td>13:53:52.8</td>\n",
       "      <td>59.86N</td>\n",
       "      <td>141.01W</td>\n",
       "      <td>SOUTHERN ITALY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2019-09-19</td>\n",
       "      <td>13:36:30.0</td>\n",
       "      <td>11.65N</td>\n",
       "      <td>87.16W</td>\n",
       "      <td>SOUTH OF ALASKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2019-09-19</td>\n",
       "      <td>13:16:31.0</td>\n",
       "      <td>31.52S</td>\n",
       "      <td>71.55W</td>\n",
       "      <td>ALASKA PENINSULA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2019-09-19</td>\n",
       "      <td>12:49:53.2</td>\n",
       "      <td>35.84N</td>\n",
       "      <td>98.09W</td>\n",
       "      <td>WESTERN AUSTRALIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2019-09-19</td>\n",
       "      <td>12:29:24.0</td>\n",
       "      <td>38.22S</td>\n",
       "      <td>69.55W</td>\n",
       "      <td>SOUTHERN CALIFORNIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2019-09-19</td>\n",
       "      <td>12:06:32.6</td>\n",
       "      <td>42.09N</td>\n",
       "      <td>41.10E</td>\n",
       "      <td>OFFSHORE ANTOFAGASTA, CHILE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2019-09-19</td>\n",
       "      <td>11:49:59.0</td>\n",
       "      <td>37.07N</td>\n",
       "      <td>5.23W</td>\n",
       "      <td>ANTOFAGASTA, CHILE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2019-09-19</td>\n",
       "      <td>11:19:00.0</td>\n",
       "      <td>35.74N</td>\n",
       "      <td>0.88W</td>\n",
       "      <td>WESTERN AUSTRALIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2019-09-19</td>\n",
       "      <td>10:46:07.9</td>\n",
       "      <td>19.38N</td>\n",
       "      <td>155.42W</td>\n",
       "      <td>SOUTHEASTERN ALASKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2019-09-19</td>\n",
       "      <td>10:32:04.2</td>\n",
       "      <td>5.90S</td>\n",
       "      <td>125.91E</td>\n",
       "      <td>SOUTH OF FIJI ISLANDS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2019-09-19</td>\n",
       "      <td>10:10:35.5</td>\n",
       "      <td>35.28N</td>\n",
       "      <td>97.93W</td>\n",
       "      <td>NEAR COAST OF NICARAGUA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2019-09-19</td>\n",
       "      <td>10:00:49.9</td>\n",
       "      <td>39.62N</td>\n",
       "      <td>38.62E</td>\n",
       "      <td>WESTERN AUSTRALIA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date        time latitude longitude                        region\n",
       "0   2019-09-19  17:55:15.0    2.04S    81.04W         NEAR COAST OF ECUADOR\n",
       "1   2019-09-19  16:51:11.8   38.34N   121.50W                CENTRAL ALASKA\n",
       "2   2019-09-19  16:43:38.0   19.64N    69.58W           NORTHERN CALIFORNIA\n",
       "3   2019-09-19  15:42:11.5   30.44S   117.66E      ISLAND OF HAWAII, HAWAII\n",
       "4   2019-09-19  15:04:22.0   41.84N    14.85E     DOMINICAN REPUBLIC REGION\n",
       "5   2019-09-19  14:34:54.4   58.36N   155.89W                  TONGA REGION\n",
       "6   2019-09-19  14:29:59.6   35.06N   117.46W             WESTERN AUSTRALIA\n",
       "7   2019-09-19  14:07:19.0   21.84S    68.51W                WESTERN TURKEY\n",
       "8   2019-09-19  13:53:52.8   59.86N   141.01W                SOUTHERN ITALY\n",
       "9   2019-09-19  13:36:30.0   11.65N    87.16W               SOUTH OF ALASKA\n",
       "10  2019-09-19  13:16:31.0   31.52S    71.55W              ALASKA PENINSULA\n",
       "11  2019-09-19  12:49:53.2   35.84N    98.09W             WESTERN AUSTRALIA\n",
       "12  2019-09-19  12:29:24.0   38.22S    69.55W           SOUTHERN CALIFORNIA\n",
       "13  2019-09-19  12:06:32.6   42.09N    41.10E   OFFSHORE ANTOFAGASTA, CHILE\n",
       "14  2019-09-19  11:49:59.0   37.07N     5.23W            ANTOFAGASTA, CHILE\n",
       "15  2019-09-19  11:19:00.0   35.74N     0.88W             WESTERN AUSTRALIA\n",
       "16  2019-09-19  10:46:07.9   19.38N   155.42W           SOUTHEASTERN ALASKA\n",
       "17  2019-09-19  10:32:04.2    5.90S   125.91E         SOUTH OF FIJI ISLANDS\n",
       "18  2019-09-19  10:10:35.5   35.28N    97.93W       NEAR COAST OF NICARAGUA\n",
       "19  2019-09-19  10:00:49.9   39.62N    38.62E             WESTERN AUSTRALIA"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.emsc-csem.org/Earthquake/'\n",
    "soup = bs(r.get(url).content, 'lxml')\n",
    "\n",
    "objects = pd.Series([str(i) for i in soup.find_all('tr', 'ligne1 normal')])\n",
    "date = objects.str.extract('(\\d{4}-\\d{2}-\\d{2})')\n",
    "time = objects.str.extract('(\\d{2}:\\d{2}:\\d{2}.\\d{1})')\n",
    "latitude = objects.str.extract('(\\d+\\.\\d+\\xa0</td><td class=\"tabev2\">[NS])')[0].str.replace('\\xa0</td><td class=\"tabev2\">', '')\n",
    "longitude = objects.str.extract('(\\d+\\.\\d+\\xa0</td><td class=\"tabev2\">[EW])')[0].str.replace('\\xa0</td><td class=\"tabev2\">', '')\n",
    "\n",
    "objects = pd.Series([str(i) for i in soup.find_all('td', 'tb_region')])\n",
    "region = pd.Series([i[1] for i in objects.str.split('>')]).str.strip('</td')\n",
    "\n",
    "eqs = pd.concat([date, time, latitude, longitude, region], axis = 1)\n",
    "eqs.columns = ['date', 'time', 'latitude', 'longitude', 'region']\n",
    "eqs.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the date, days, title, city, country of next 25 hackathon events as a Pandas dataframe table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url ='https://hackevents.co/hackathons'\n",
    "soup = bs(r.get(url).content, 'lxml')\n",
    "soup.find_all('p')\n",
    "\n",
    "# skipped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count number of tweets by a given Twitter account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to include a ***try/except block*** for account names not found. \n",
    "<br>***Hint:*** the program should count the number of tweets for any provided account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<span class=\"ProfileNav-value\" data-count=\"30150\" data-is-compact=\"true\">30.2K\n",
      "            </span>\n",
      "<span class=\"ProfileNav-value\" data-count=\"148\" data-is-compact=\"false\">148</span>\n",
      "<span class=\"ProfileNav-value\" data-count=\"61854742\" data-is-compact=\"true\">61.9M</span>\n",
      "<span class=\"ProfileNav-value\" data-count=\"87\" data-is-compact=\"false\">87</span>\n",
      "<span class=\"ProfileNav-value\">More <span class=\"ProfileNav-dropdownCaret Icon Icon--medium Icon--caretDown\"></span></span>\n"
     ]
    }
   ],
   "source": [
    "url = 'https://twitter.com/KimKardashian'\n",
    "soup = bs(r.get(url).content, 'lxml')\n",
    "\n",
    "objects = pd.Series([str(i) for i in soup.find_all('span', 'ProfileNav-value')])\n",
    "tweets = pd.Series([i[1] for i in objects.str.split('>')])[0].strip('\\n            </span')\n",
    "for i in objects:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of followers of a given twitter account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to include a ***try/except block*** in case account/s name not found. \n",
    "<br>***Hint:*** the program should count the followers for any provided account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'61.8M'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://twitter.com/KimKardashian'\n",
    "soup = bs(r.get(url).content, 'lxml')\n",
    "\n",
    "objects = pd.Series([str(i) for i in soup.find_all('span', 'ProfileNav-value')])\n",
    "followers = pd.Series([i[1] for i in objects.str.split('>')])[2].strip('</span')\n",
    "followers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List all language names and number of related articles in the order they appear in wikipedia.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>languages</th>\n",
       "      <th>articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English</td>\n",
       "      <td>5,930,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Español</td>\n",
       "      <td>1,545,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>日本語</td>\n",
       "      <td>1,168,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deutsch</td>\n",
       "      <td>2,343,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Русский</td>\n",
       "      <td>1,568,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Françai</td>\n",
       "      <td>2,139,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Italia</td>\n",
       "      <td>1,552,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>中文</td>\n",
       "      <td>1,073,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Portuguê</td>\n",
       "      <td>1,013,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Polski</td>\n",
       "      <td>1,359,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  languages   articles\n",
       "0   English  5,930,000\n",
       "1   Español  1,545,000\n",
       "2       日本語  1,168,000\n",
       "3   Deutsch  2,343,000\n",
       "4   Русский  1,568,000\n",
       "5   Françai  2,139,000\n",
       "6    Italia  1,552,000\n",
       "7        中文  1,073,000\n",
       "8  Portuguê  1,013,000\n",
       "9    Polski  1,359,000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.wikipedia.org/'\n",
    "soup = bs(r.get(url).content, 'lxml')\n",
    "\n",
    "objects = pd.Series([str(i) for i in soup.find_all('a', 'link-box')])\n",
    "languages = pd.Series([i[2] for i in objects.str.split('>')]).str.strip('</strong')\n",
    "articles = pd.Series([i[5] for i in objects.str.split('>')]).str.replace('\\xa0', ',').str.strip('+</bdi')\n",
    "\n",
    "wiki = pd.concat([languages, articles], axis = 1)\n",
    "wiki.columns = ['languages', 'articles']\n",
    "wiki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A list with the different kind of datasets available in data.gov.uk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Business and economy',\n",
       " 'Crime and justice',\n",
       " 'Defence',\n",
       " 'Education',\n",
       " 'Environment',\n",
       " 'Government',\n",
       " 'Government spending',\n",
       " 'Healt',\n",
       " 'Mapping',\n",
       " 'Society',\n",
       " 'Towns and cities',\n",
       " 'Transport']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://data.gov.uk/'\n",
    "soup = bs(r.get(url).content, 'lxml')\n",
    "\n",
    "objects = pd.Series([str(i) for i in soup.find_all('h2')])\n",
    "datasets = pd.Series([i[2] for i in objects.str.split('\"')]).str.strip('>|</a></h2').to_list()\n",
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 languages by number of native speakers stored in a Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mandarin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hindi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bengali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Portuguese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Japanese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Western Punjabi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Marathi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "0         Mandarin\n",
       "1          Spanish\n",
       "2          English\n",
       "3            Hindi\n",
       "4          Bengali\n",
       "5       Portuguese\n",
       "6          Russian\n",
       "7         Japanese\n",
       "8  Western Punjabi\n",
       "9          Marathi"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers'\n",
    "soup = bs(r.get(url).content, 'lxml')\n",
    "objects = pd.Series([str(i) for i in soup.find_all('tr')])\n",
    "languages = pd.Series([i[5] for i in objects.str.split('>') if i[5] != '\\n<th']).str.strip('</a')\n",
    "pd.DataFrame(languages).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS QUESTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrape a certain number of tweets of a given Twitter account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     I know we are sold out of almost all <a class=...\n",
       "1     Kim Kardashian is Launching a Scented Candle S...\n",
       "2     4\" lang=\"und\"><img alt=\"😂\" aria-label=\"Emoji: ...\n",
       "3     I am obsessed with our <a class=\"twitter-atrep...\n",
       "4     y pretty-link js-nav\" data-mentioned-user-id=\"...\n",
       "5     I’m so excited to announce my new <a class=\"tw...\n",
       "6     4\" lang=\"en\">Next week is the most intense<a c...\n",
       "7     Epic happy birthday song by <a class=\"twitter-...\n",
       "8                      Kourt’s party was so much fun!!!\n",
       "9     4\" lang=\"en\">We try not to dwell<a class=\"twit...\n",
       "10    4\" lang=\"en\">BIG FACTS<a class=\"twitter-timeli...\n",
       "11    4\" lang=\"en\">FACTS<a class=\"twitter-timeline-l...\n",
       "12    Kourt got so emotional with all of the Disney ...\n",
       "13    4\" lang=\"en\">Fighting is over don’t worry <img...\n",
       "14    4\" lang=\"en\">Absolutely get mad at all over ag...\n",
       "15    4\" lang=\"und\"><img alt=\"🤦🏻‍♀️\" aria-label=\"Emo...\n",
       "16    4\" lang=\"und\"><img alt=\"😂\" aria-label=\"Emoji: ...\n",
       "17    “fake humanitarian hoe” <a class=\"twitter-hash...\n",
       "18    4\" lang=\"en\">Don’t get me started!!!<a class=\"...\n",
       "19    Literally the second <a class=\"twitter-atreply...\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://twitter.com/KimKardashian'\n",
    "soup = bs(r.get(url).content, 'lxml')\n",
    "\n",
    "objects = pd.Series([str(i) for i in soup.find_all('p', 'TweetTextSize TweetTextSize--normal js-tweet-text tweet-text')])\n",
    "tweets = objects.str.strip('<p class=\"TweetTextSize TweetTextSize--normal js-tweet-text tweet-text\" data-aria-label-part=\"0\" lang=\"en\">|<a class=\"twitter-timeline-link u-hidden\" data-pre-embedded=\"true\" dir=\"ltr\" href=\"https://t.co/XkFPxpRuz7\">pic.twitter.com/XkFPxpRuz7</a></')\n",
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMDB's Top 250 data (movie name, Initial release, director name and stars) as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>release</th>\n",
       "      <th>director</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>1994</td>\n",
       "      <td>Frank Darabont</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>1972</td>\n",
       "      <td>Francis Ford Coppola</td>\n",
       "      <td>9.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>1974</td>\n",
       "      <td>Francis Ford Coppola</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>2008</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>1957</td>\n",
       "      <td>Sidney Lumet</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Schindler's List</td>\n",
       "      <td>1993</td>\n",
       "      <td>Steven Spielberg</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Lord of the Rings: The Return of the King</td>\n",
       "      <td>2003</td>\n",
       "      <td>Peter Jackson</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pulp Fiction</td>\n",
       "      <td>1994</td>\n",
       "      <td>Quentin Tarantino</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Good, the Bad and the Ugly</td>\n",
       "      <td>1966</td>\n",
       "      <td>Sergio Leone</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fight Club</td>\n",
       "      <td>1999</td>\n",
       "      <td>David Fincher</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The Lord of the Rings: The Fellowship of the Ring</td>\n",
       "      <td>2001</td>\n",
       "      <td>Peter Jackson</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Forrest Gump</td>\n",
       "      <td>1994</td>\n",
       "      <td>Robert Zemeckis</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Inception</td>\n",
       "      <td>2010</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Star Wars: Episode V - The Empire Strikes Back</td>\n",
       "      <td>1980</td>\n",
       "      <td>Irvin Kershner</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The Lord of the Rings: The Two Towers</td>\n",
       "      <td>2002</td>\n",
       "      <td>Peter Jackson</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The Matrix</td>\n",
       "      <td>1999</td>\n",
       "      <td>Lana Wachowski</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>One Flew Over the Cuckoo's Nest</td>\n",
       "      <td>1975</td>\n",
       "      <td>Milos Forman</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Goodfellas</td>\n",
       "      <td>1990</td>\n",
       "      <td>Martin Scorsese</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Seven Samurai</td>\n",
       "      <td>1954</td>\n",
       "      <td>Akira Kurosawa</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Se7en</td>\n",
       "      <td>1995</td>\n",
       "      <td>David Fincher</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>City of God</td>\n",
       "      <td>2002</td>\n",
       "      <td>Fernando Meirelles</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Life Is Beautiful</td>\n",
       "      <td>1997</td>\n",
       "      <td>Roberto Benigni</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>The Silence of the Lambs</td>\n",
       "      <td>1991</td>\n",
       "      <td>Jonathan Demme</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Star Wars: Episode IV - A New Hope</td>\n",
       "      <td>1977</td>\n",
       "      <td>George Lucas</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>It's a Wonderful Life</td>\n",
       "      <td>1946</td>\n",
       "      <td>Frank Capra</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Saving Private Ryan</td>\n",
       "      <td>1998</td>\n",
       "      <td>Steven Spielberg</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Spirited Away</td>\n",
       "      <td>2001</td>\n",
       "      <td>Hayao Miyazaki</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>The Green Mile</td>\n",
       "      <td>1999</td>\n",
       "      <td>Frank Darabont</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Harakiri</td>\n",
       "      <td>1962</td>\n",
       "      <td>Masaki Kobayashi</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Léon: The Professional</td>\n",
       "      <td>1994</td>\n",
       "      <td>Luc Besson</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>Dead Poets Society</td>\n",
       "      <td>1989</td>\n",
       "      <td>Peter Weir</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>Rebecc</td>\n",
       "      <td>1940</td>\n",
       "      <td>Alfred Hitchcock</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>Toy Story 4</td>\n",
       "      <td>2019</td>\n",
       "      <td>Josh Cooley</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>Rocky</td>\n",
       "      <td>1976</td>\n",
       "      <td>John G. Avildsen</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>Gangs of Wasseypur</td>\n",
       "      <td>2012</td>\n",
       "      <td>Anurag Kashyap</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>Monsters, Inc.</td>\n",
       "      <td>2001</td>\n",
       "      <td>Pete Docter</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>It Happened One Night</td>\n",
       "      <td>1934</td>\n",
       "      <td>Frank Capra</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>Lagaan: Once Upon a Time in Indi</td>\n",
       "      <td>2001</td>\n",
       "      <td>Ashutosh Gowariker</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>La Haine</td>\n",
       "      <td>1995</td>\n",
       "      <td>Mathieu Kassovitz</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>The Handmaiden</td>\n",
       "      <td>2016</td>\n",
       "      <td>Chan-wook Park</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>Munna Bhai M.B.B.S.</td>\n",
       "      <td>2003</td>\n",
       "      <td>Rajkumar Hirani</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>The Exterminating Angel</td>\n",
       "      <td>1962</td>\n",
       "      <td>Luis Buñuel</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>The Princess Bride</td>\n",
       "      <td>1987</td>\n",
       "      <td>Rob Reiner</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>PK</td>\n",
       "      <td>2014</td>\n",
       "      <td>Rajkumar Hirani</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>Swades</td>\n",
       "      <td>2004</td>\n",
       "      <td>Ashutosh Gowariker</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>Butch Cassidy and the Sundance Kid</td>\n",
       "      <td>1969</td>\n",
       "      <td>George Roy Hill</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>The Help</td>\n",
       "      <td>2011</td>\n",
       "      <td>Tate Taylor</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>Before Sunset</td>\n",
       "      <td>2004</td>\n",
       "      <td>Richard Linklater</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>Drishyam</td>\n",
       "      <td>2015</td>\n",
       "      <td>Nishikant Kamat</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>Akir</td>\n",
       "      <td>1988</td>\n",
       "      <td>Katsuhiro Ôtomo</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>Paris, Texas</td>\n",
       "      <td>1984</td>\n",
       "      <td>Wim Wenders</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>The Terminator</td>\n",
       "      <td>1984</td>\n",
       "      <td>James Cameron</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>In the Mood for Love</td>\n",
       "      <td>2000</td>\n",
       "      <td>Kar-Wai Wong</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>Guardians of the Galaxy</td>\n",
       "      <td>2014</td>\n",
       "      <td>James Gunn</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>Infernal Affairs</td>\n",
       "      <td>2002</td>\n",
       "      <td>Andrew Lau Wai-Keung</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>A Wednesday</td>\n",
       "      <td>2008</td>\n",
       "      <td>Neeraj Pandey</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>The Battle of Algiers</td>\n",
       "      <td>1966</td>\n",
       "      <td>Gillo Pontecorvo</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>La leggenda del pianista sull'oceano</td>\n",
       "      <td>1998</td>\n",
       "      <td>Giuseppe Tornatore</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>Aladdin</td>\n",
       "      <td>1992</td>\n",
       "      <td>Ron Clements</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Kis Uykusu</td>\n",
       "      <td>2014</td>\n",
       "      <td>Nuri Bilge Ceylan</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title release  \\\n",
       "0                             The Shawshank Redemption    1994   \n",
       "1                                        The Godfather    1972   \n",
       "2                               The Godfather: Part II    1974   \n",
       "3                                      The Dark Knight    2008   \n",
       "4                                         12 Angry Men    1957   \n",
       "5                                     Schindler's List    1993   \n",
       "6        The Lord of the Rings: The Return of the King    2003   \n",
       "7                                         Pulp Fiction    1994   \n",
       "8                       The Good, the Bad and the Ugly    1966   \n",
       "9                                           Fight Club    1999   \n",
       "10   The Lord of the Rings: The Fellowship of the Ring    2001   \n",
       "11                                        Forrest Gump    1994   \n",
       "12                                           Inception    2010   \n",
       "13      Star Wars: Episode V - The Empire Strikes Back    1980   \n",
       "14               The Lord of the Rings: The Two Towers    2002   \n",
       "15                                          The Matrix    1999   \n",
       "16                     One Flew Over the Cuckoo's Nest    1975   \n",
       "17                                          Goodfellas    1990   \n",
       "18                                       Seven Samurai    1954   \n",
       "19                                               Se7en    1995   \n",
       "20                                         City of God    2002   \n",
       "21                                   Life Is Beautiful    1997   \n",
       "22                            The Silence of the Lambs    1991   \n",
       "23                  Star Wars: Episode IV - A New Hope    1977   \n",
       "24                               It's a Wonderful Life    1946   \n",
       "25                                 Saving Private Ryan    1998   \n",
       "26                                       Spirited Away    2001   \n",
       "27                                      The Green Mile    1999   \n",
       "28                                            Harakiri    1962   \n",
       "29                              Léon: The Professional    1994   \n",
       "..                                                 ...     ...   \n",
       "220                                 Dead Poets Society    1989   \n",
       "221                                             Rebecc    1940   \n",
       "222                                        Toy Story 4    2019   \n",
       "223                                              Rocky    1976   \n",
       "224                                 Gangs of Wasseypur    2012   \n",
       "225                                     Monsters, Inc.    2001   \n",
       "226                              It Happened One Night    1934   \n",
       "227                   Lagaan: Once Upon a Time in Indi    2001   \n",
       "228                                           La Haine    1995   \n",
       "229                                     The Handmaiden    2016   \n",
       "230                                Munna Bhai M.B.B.S.    2003   \n",
       "231                            The Exterminating Angel    1962   \n",
       "232                                 The Princess Bride    1987   \n",
       "233                                                 PK    2014   \n",
       "234                                             Swades    2004   \n",
       "235                 Butch Cassidy and the Sundance Kid    1969   \n",
       "236                                           The Help    2011   \n",
       "237                                      Before Sunset    2004   \n",
       "238                                           Drishyam    2015   \n",
       "239                                               Akir    1988   \n",
       "240                                       Paris, Texas    1984   \n",
       "241                                     The Terminator    1984   \n",
       "242                               In the Mood for Love    2000   \n",
       "243                            Guardians of the Galaxy    2014   \n",
       "244                                   Infernal Affairs    2002   \n",
       "245                                        A Wednesday    2008   \n",
       "246                              The Battle of Algiers    1966   \n",
       "247               La leggenda del pianista sull'oceano    1998   \n",
       "248                                            Aladdin    1992   \n",
       "249                                         Kis Uykusu    2014   \n",
       "\n",
       "                 director stars  \n",
       "0          Frank Darabont   9.2  \n",
       "1    Francis Ford Coppola   9.1  \n",
       "2    Francis Ford Coppola   9.0  \n",
       "3       Christopher Nolan   9.0  \n",
       "4            Sidney Lumet   8.9  \n",
       "5        Steven Spielberg   8.9  \n",
       "6           Peter Jackson   8.9  \n",
       "7       Quentin Tarantino   8.9  \n",
       "8            Sergio Leone   8.8  \n",
       "9           David Fincher   8.8  \n",
       "10          Peter Jackson   8.8  \n",
       "11        Robert Zemeckis   8.8  \n",
       "12      Christopher Nolan   8.7  \n",
       "13         Irvin Kershner   8.7  \n",
       "14          Peter Jackson   8.7  \n",
       "15         Lana Wachowski   8.6  \n",
       "16           Milos Forman   8.6  \n",
       "17        Martin Scorsese   8.6  \n",
       "18         Akira Kurosawa   8.6  \n",
       "19          David Fincher   8.6  \n",
       "20     Fernando Meirelles   8.6  \n",
       "21        Roberto Benigni   8.6  \n",
       "22         Jonathan Demme   8.6  \n",
       "23           George Lucas   8.6  \n",
       "24            Frank Capra   8.6  \n",
       "25       Steven Spielberg   8.5  \n",
       "26         Hayao Miyazaki   8.5  \n",
       "27         Frank Darabont   8.5  \n",
       "28       Masaki Kobayashi   8.5  \n",
       "29             Luc Besson   8.5  \n",
       "..                    ...   ...  \n",
       "220            Peter Weir   8.0  \n",
       "221      Alfred Hitchcock   8.0  \n",
       "222           Josh Cooley   8.0  \n",
       "223      John G. Avildsen   8.0  \n",
       "224        Anurag Kashyap   8.0  \n",
       "225           Pete Docter   8.0  \n",
       "226           Frank Capra   8.0  \n",
       "227    Ashutosh Gowariker   8.0  \n",
       "228     Mathieu Kassovitz   8.0  \n",
       "229        Chan-wook Park   8.0  \n",
       "230       Rajkumar Hirani   8.0  \n",
       "231           Luis Buñuel   8.0  \n",
       "232            Rob Reiner   8.0  \n",
       "233       Rajkumar Hirani   8.0  \n",
       "234    Ashutosh Gowariker   8.0  \n",
       "235       George Roy Hill   8.0  \n",
       "236           Tate Taylor   8.0  \n",
       "237     Richard Linklater   8.0  \n",
       "238       Nishikant Kamat   8.0  \n",
       "239       Katsuhiro Ôtomo   8.0  \n",
       "240           Wim Wenders   8.0  \n",
       "241         James Cameron   8.0  \n",
       "242          Kar-Wai Wong   8.0  \n",
       "243            James Gunn   8.0  \n",
       "244  Andrew Lau Wai-Keung   8.0  \n",
       "245         Neeraj Pandey   8.0  \n",
       "246      Gillo Pontecorvo   8.0  \n",
       "247    Giuseppe Tornatore   8.0  \n",
       "248          Ron Clements   8.0  \n",
       "249     Nuri Bilge Ceylan   8.0  \n",
       "\n",
       "[250 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.imdb.com/chart/top'\n",
    "soup = bs(r.get(url).content, 'lxml')\n",
    "\n",
    "objects = pd.Series([str(i) for i in soup.find_all('td', 'titleColumn')])\n",
    "director = pd.Series([i[1] for i in objects.str.split('>')]).str.replace('^(?:.|\\n)*title=\"', '').str.replace(' \\(dir\\.\\)(?:.|\\n)*$', '')\n",
    "title = pd.Series([i[2] for i in objects.str.split('>')]).str.strip('</a')\n",
    "release = pd.Series([i[4] for i in objects.str.split('>')]).str.extract('(\\d{4})')\n",
    "\n",
    "objects = pd.Series([str(i) for i in soup.find_all('td', 'ratingColumn imdbRating')])\n",
    "stars = pd.Series([i[1] for i in objects.str.split('>')]).str.extract('(\\d{1}\\.\\d{1})')\n",
    "\n",
    "imdb = pd.concat([title, release, director, stars], axis = 1)\n",
    "imdb.columns = ['title', 'release', 'director', 'stars']\n",
    "imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Movie name, year and a brief summary of the top 10 random movies (IMDB) as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fight Club</td>\n",
       "      <td>1999</td>\n",
       "      <td>An insomniac office worker and a devil-may-car...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alien</td>\n",
       "      <td>1979</td>\n",
       "      <td>After a space merchant vessel perceives an unk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pulp Fiction</td>\n",
       "      <td>1994</td>\n",
       "      <td>The lives of two mob hitmen, a boxer, a gangst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hotel Rwanda</td>\n",
       "      <td>2004</td>\n",
       "      <td>Paul Rusesabagina was a hotel manager who hous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kill Bill: Vol. 1</td>\n",
       "      <td>2003</td>\n",
       "      <td>After awakening from a four-year coma, a forme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rear Window</td>\n",
       "      <td>1954</td>\n",
       "      <td>A wheelchair-bound photographer spies on his n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Hunt</td>\n",
       "      <td>2012</td>\n",
       "      <td>A teacher lives a lonely life, all the while s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Matrix</td>\n",
       "      <td>1999</td>\n",
       "      <td>A computer hacker learns from mysterious rebel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rebecca</td>\n",
       "      <td>1940</td>\n",
       "      <td>A self-conscious woman juggles adjusting to he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Nausicaä of the Valley of the Wind</td>\n",
       "      <td>1984</td>\n",
       "      <td>Warrior and pacifist Princess Nausicaä despera...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                title  year  \\\n",
       "0                          Fight Club  1999   \n",
       "1                               Alien  1979   \n",
       "2                        Pulp Fiction  1994   \n",
       "3                        Hotel Rwanda  2004   \n",
       "4                   Kill Bill: Vol. 1  2003   \n",
       "5                         Rear Window  1954   \n",
       "6                            The Hunt  2012   \n",
       "7                          The Matrix  1999   \n",
       "8                             Rebecca  1940   \n",
       "9  Nausicaä of the Valley of the Wind  1984   \n",
       "\n",
       "                                             summary  \n",
       "0  An insomniac office worker and a devil-may-car...  \n",
       "1  After a space merchant vessel perceives an unk...  \n",
       "2  The lives of two mob hitmen, a boxer, a gangst...  \n",
       "3  Paul Rusesabagina was a hotel manager who hous...  \n",
       "4  After awakening from a four-year coma, a forme...  \n",
       "5  A wheelchair-bound photographer spies on his n...  \n",
       "6  A teacher lives a lonely life, all the while s...  \n",
       "7  A computer hacker learns from mysterious rebel...  \n",
       "8  A self-conscious woman juggles adjusting to he...  \n",
       "9  Warrior and pacifist Princess Nausicaä despera...  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'http://www.imdb.com/chart/top'\n",
    "soup = bs(r.get(url).content, 'lxml')\n",
    "\n",
    "objects = pd.Series([str(i) for i in soup.find_all('td', 'posterColumn')])\n",
    "links = ('https://www.imdb.com' + pd.Series([i[11] for i in objects.str.split('>')]).str.strip('\\n<a href=\"')).to_list()\n",
    "randoms = random.sample(links, 10)\n",
    "\n",
    "title = []\n",
    "year = []\n",
    "summary = []\n",
    "\n",
    "for i in randoms:\n",
    "    soup = bs(r.get(i).content, 'lxml')\n",
    "    title.append(str(soup.find_all('h1', '')).split('>')[1].replace('\\xa0<span id=\"titleYear\"', ''))\n",
    "    year.append(str(soup.find_all('span', {'id': 'titleYear'})).split('>')[2].replace('</a', ''))\n",
    "    summary.append(re.sub('\\n +</div$', '', re.sub('^\\n +', '', str(soup.find_all('div', 'summary_text')).split('>')[1])))\n",
    "\n",
    "pd.DataFrame({'title': title, 'year': year, 'summary': summary})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the live weather report (temperature, wind speed, description and weather) of a given city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://openweathermap.org/current\n",
    "city = input('Enter the city: ')\n",
    "url = 'http://api.openweathermap.org/data/2.5/weather?'+'q='+city+'&APPID=b35975e18dc93725acb092f7272cc6b8&units=metric'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Book name,price and stock availability as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise. \n",
    "# It is a fictional bookstore created to be scraped. \n",
    "url = 'http://books.toscrape.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
