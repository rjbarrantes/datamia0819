NEURAL NETWORKS

artificial neural network (ann)
  input layer
    independent variables (Xi)
    row by row
    synapse
      Wi associated with each Xi
  nodes
    hidden layers
    (activation fx) * (sum of Xi*Wi)
  output layer
    Yi prediction for each row

  activation functions
    threshold = piecewise function where 0 for x <= 0 and 1 for x > 0
    sigmoid = s-shaped curve (x: -inf, +inf, y: 0, 1)
    rectified = 0 for x <= 0, and linearly increasing for x > 0
    tanh = like sigmoid but stretched across y (x: -inf, +inf, y: -1, 1)

  forward propagation
    data fed in to determine output

  back propagation
    comparison of predictions and actual values
    the goal is to minimize cost or loss function (based on residuals)
      epoch = goes through entire dataset
      gradient descent = update weights batch by batch
      stochastic gradient descent = update weights row by row
        computationally faster since not having to take entire dataset into account for each weight adjustment
        more likely to find global minimum because weights fluctuate more
      minibatch = between gradient and stochastic gradient descents

  common 
    apply rectified in hidden layers
    activation of output layer depends on y
      binary = threshold or sigmoid (P(y = 0) or P(y = 1))

  steps
    randomly initialize weights (close to 0)
    input first observation in input layer (each feature as one input node)
    forward propagation (find y-hat)
    compare y and y-hat to get error
    back propagation (learning rate determines how much weights are updated)
    repeat for all observations
    epoch completed and repeat

convolutional neural networks (cnn)
  used for image recognition
  
  feature detector (kernel)
    typically 3x3, but can be any odd combo (5x5, 7x7, etc.)
    convolutional operation = x in a circle
  
  feature map = sum of element-wise multiplication of kernel and 3x3 slice of image
    convolved feature
    stride = step at which the kernel moves through the image
      typically 2, but default in keras is 1
    maintains spacial relationships
  
  convolutional layer = series of feature maps
    rectifier used to allow for non-linearity in intermediate layers

  pooling
    allows for spacial invariance and reduces the size
    can be max, mean, sum, etc. type of pooling
    applied to feature maps
      typically done with 2x2 squares and stride of 2

  flattening
    take values in pooled layer into a flattened input layer for the ann

  full connection
    addition of ann to the back of cnn
    allows for better predictions from features extracted by cnn
    



